{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing dataset\n",
    "lines=open('movie_lines.txt',encoding='utf-8',errors='ignore').read().split('\\n')\n",
    "conversations=open('movie_conversations.txt',encoding='utf-8',errors='ignore').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304714\n"
     ]
    }
   ],
   "source": [
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a dictionary with maps each line with its id\n",
    "id2line={}\n",
    "for line in lines:\n",
    "    temp_line=line.split(' +++$+++ ')\n",
    "    if(len(temp_line)==5):\n",
    "        id2line[temp_line[0]]=temp_line[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304713\n"
     ]
    }
   ],
   "source": [
    "print(len(id2line.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating list of all conversations\n",
    "conversations_ids=[]\n",
    "for conv in conversations[:-1]:\n",
    "    conv_temp=conv.split(' +++$+++ ')[-1][1:-1].replace(\"'\",\"\").replace(\" \",\"\")\n",
    "    conversations_ids.append(conv_temp.split(','))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting separately the questions and answers\n",
    "questions=[]\n",
    "answers=[]\n",
    "for conversation in conversations_ids:\n",
    "    for i in range(len(conversation)-1):\n",
    "        questions.append(id2line[conversation[i]])\n",
    "        answers.append(id2line[conversation[i+1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\n",
      "Well, I thought we'd start with pronunciation, if that's okay with you.\n"
     ]
    }
   ],
   "source": [
    "print(questions[0])\n",
    "print(answers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLeaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_text(text):\n",
    "    text=text.lower()\n",
    "    text=re.sub(r\"i'm\",\"i am\",text)\n",
    "    text=re.sub(r\"he's\",\"he is\",text)\n",
    "    text=re.sub(r\"she's\",\"she is\",text)\n",
    "    text=re.sub(r\"that's\",\"that is\",text)\n",
    "    text=re.sub(r\"what's\",\"what is\",text)\n",
    "    text=re.sub(r\"where's\",\"where is\",text)\n",
    "    text=re.sub(r\"\\'ll\",\"will\",text)\n",
    "    text=re.sub(r\"\\'ve\",\"have\",text)\n",
    "    text=re.sub(r\"\\'re\",\"are\",text)\n",
    "    text=re.sub(r\"\\'d\",\"would\",text)\n",
    "    text=re.sub(r\"won't\",\"will not\",text)\n",
    "    text=re.sub(r\"don't\",\"do not\",text)\n",
    "    text=re.sub(r\"can't\",\"cannot\",text)\n",
    "    text=re.sub(r\"it's\",\"it is\",text)\n",
    "    text=re.sub(r\"[-()\\#/@;<>{}+=|.?,]\",\"\",text)\n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_questions=[]\n",
    "for question in questions:\n",
    "    clean_questions.append(clean_text(question))\n",
    "\n",
    "clean_answers=[]\n",
    "for answer in answers:\n",
    "    clean_answers.append(clean_text(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what about back home\n"
     ]
    }
   ],
   "source": [
    "print(clean_answers[700])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dictionary that maps each words to its number of occurences\n",
    "word2count={}\n",
    "for question in clean_questions:\n",
    "    for word in question.split():\n",
    "        if(word not in word2count):\n",
    "            word2count[word]=1\n",
    "        else:\n",
    "            word2count[word]+=1\n",
    "\n",
    "for answer in clean_answers:\n",
    "    for word in answer.split():\n",
    "        if(word not in word2count):\n",
    "            word2count[word]=1\n",
    "        else:\n",
    "            word2count[word]+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182808"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2count['i']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating 2 dictionaries which map the questions words and the answers word to a integer and filter out words which are boyond a threshold\n",
    "threshold=20\n",
    "questionswords2int={}\n",
    "word_number=0\n",
    "for word,count in word2count.items():\n",
    "    if(count>threshold):\n",
    "        questionswords2int[word]=word_number\n",
    "        word_number+=1\n",
    "\n",
    "\n",
    "answerswords2int={}\n",
    "word_number=0\n",
    "for word,count in word2count.items():\n",
    "    if(count>threshold):\n",
    "        answerswords2int[word]=word_number\n",
    "        word_number+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding more tokens\n",
    "\n",
    "tokens=['<PAD>','<EOS>','<OUT>','<SOS>']\n",
    "for token in tokens:\n",
    "    questionswords2int[token]=len(questionswords2int)+1\n",
    "\n",
    "for token in tokens:\n",
    "    answerswords2int[token]=len(answerswords2int)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inverse dictionary\n",
    "answersint2word={w_i:w for w,w_i in answerswords2int.items()}\n",
    "#questionsint2word={w_i:for w,w_i in questionswords2int.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add EOS to end of every answer\n",
    "for i in range(len(clean_answers)):\n",
    "    clean_answers[i]+=' <EOS>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#translated all the questions and answers into integers\n",
    "questions2int=[]\n",
    "for question in clean_questions:\n",
    "    ints=[]\n",
    "    for word in question.split():\n",
    "        if(word not in questionswords2int):\n",
    "            ints.append(questionswords2int['<OUT>'])\n",
    "        else:\n",
    "            ints.append(questionswords2int[word])\n",
    "    questions2int.append(ints)\n",
    "    \n",
    "answers2int=[]\n",
    "for answer in clean_answers:\n",
    "    ints=[]\n",
    "    for word in question.split():\n",
    "        if(word not in answerswords2int):\n",
    "            ints.append(answerswords2int['<OUT>'])\n",
    "        else:\n",
    "            ints.append(answerswords2int[word])\n",
    "    answers2int.append(ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sorting questions and answers by length of questions\n",
    "sorted_clean_questions=[]\n",
    "sorted_clean_answers=[]\n",
    "\n",
    "for length in range(1,25+1):\n",
    "    for i in enumerate(questions2int):\n",
    "        if(len(i[1])==length):\n",
    "            sorted_clean_questions.append(questions2int[i[0]])\n",
    "            sorted_clean_answers.append(answers2int[i[0]])\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5,\n",
       " 18,\n",
       " 1681,\n",
       " 27,\n",
       " 27,\n",
       " 94,\n",
       " 28,\n",
       " 111,\n",
       " 1643,\n",
       " 285,\n",
       " 67,\n",
       " 5241,\n",
       " 93,\n",
       " 38,\n",
       " 1443,\n",
       " 1619,\n",
       " 37,\n",
       " 45,\n",
       " 38,\n",
       " 6005,\n",
       " 595]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_clean_answers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[48]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_clean_questions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
